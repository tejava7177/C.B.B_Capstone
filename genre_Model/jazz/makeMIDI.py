import tensorflow as tf
import numpy as np
import pretty_midi

from music_transformer_model import MusicTransformer

# âœ… ëª¨ë¸ ë¡œë“œ
model_path = "/Users/simjuheun/Desktop/ê°œì¸í”„ë¡œì íŠ¸/C.B.B/genre_Model/jazz/music_transformer_jazz.keras"
model = tf.keras.models.load_model(model_path, custom_objects={"MusicTransformer": MusicTransformer})
print("ğŸµ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

# âœ… ì½”ë“œ ì§„í–‰ (ê° ì½”ë“œê°€ 4ë°•ì ì§€ì†)
chord_progression = [
    [60, 64, 67],  # Cmaj7
    [67, 71, 74],  # Gmaj7
    [65, 68, 72],  # Fm
    [62, 65, 69],  # Dm
    [67, 71, 74],  # Gmaj7
    [71, 74, 77],  # Bdim
    [71, 75, 79],  # Bmaj7
    [64, 68, 72],  # Emaj7
    [71, 74, 77],  # Bdim
    [65, 69, 72],  # Fsus4
]
chord_progression = np.array(chord_progression).astype(np.int32)

# âœ… Temperature Sampling í•¨ìˆ˜
def sample_with_temperature(predictions, temperature=1.2):
    predictions = np.exp(predictions / temperature)
    predictions /= np.sum(predictions)
    return np.random.choice(len(predictions), p=predictions)

# âœ… ë©œë¡œë”” & ë¦¬ë“¬ ìƒì„±
def generate_melody_and_rhythm(model, chord_progression, sequence_length=32, num_steps=4, temperature=1.2):
    generated_melody = []
    generated_rhythm = []

    input_seq = np.zeros((1, sequence_length), dtype=np.int32)
    input_seq[0, -chord_progression.flatten().shape[0]:] = chord_progression.flatten()[:sequence_length]

    for chord in chord_progression:
        for _ in range(num_steps):
            predicted_probs = model.predict(input_seq, verbose=0)[0, -1, :]
            predicted_note = sample_with_temperature(predicted_probs, temperature)  # âœ… Temperature Sampling ì‚¬ìš©

            predicted_note = np.clip(predicted_note, 0, 127)  # âœ… MIDI ë²”ìœ„ ê°•ì œ ì ìš©
            predicted_rhythm = np.random.choice([0.25, 0.5, 0.75, 1.0], p=[0.3, 0.3, 0.2, 0.2])

            generated_melody.append(predicted_note)
            generated_rhythm.append(predicted_rhythm)

            input_seq = np.roll(input_seq, -1, axis=1)
            input_seq[0, -1] = predicted_note

    return generated_melody, generated_rhythm

# âœ… ë² ì´ìŠ¤ ë¼ì¸ ìƒì„± (ì›Œí¬ ë² ì´ìŠ¤ ìŠ¤íƒ€ì¼)
def generate_bassline(chord_progression):
    bassline = []
    rhythm = []
    for chord in chord_progression:
        bass_note = np.clip(min(chord) - 12, 36, 127)  # âœ… MIDI ë²”ìœ„ ê°•ì œ ì ìš©
        bassline.extend([bass_note] * 4)
        rhythm.extend([1.0] * 4)
    return bassline, rhythm

# âœ… ğŸ¥ ë“œëŸ¼ íŒ¨í„´ ìƒì„± í•¨ìˆ˜ (ë²”ìœ„ ì œí•œ)
def generate_drum_pattern(num_bars=4):
    drum_pattern = []
    rhythm = []
    for _ in range(num_bars):
        drum_hits = [36, 38, 42]  # âœ… (Kick, Snare, HiHat) (ê°’ ì œí•œ: 35~81)
        drum_pattern.extend(drum_hits)
        rhythm.extend([1.0, 1.0, 0.5])
    return drum_pattern, rhythm

# âœ… ë°ì´í„° ìƒì„±
generated_melody, generated_rhythm = generate_melody_and_rhythm(model, chord_progression)
generated_bassline, bass_rhythm = generate_bassline(chord_progression)
generated_drums, drum_rhythm = generate_drum_pattern(len(chord_progression))


def create_midi(melody, rhythm, bassline, bass_rhythm, drums, drum_rhythm, output_path="generated_jazz.mid"):
    midi = pretty_midi.PrettyMIDI()

    def add_notes_to_instrument(inst, notes, rhythms, min_pitch, max_pitch, is_drum=False):
        start_time = 0
        for note, duration in zip(notes, rhythms):
            int_pitch = int(round(np.clip(note, min_pitch, max_pitch)))  # âœ… ì •ìˆ˜ ë³€í™˜
            int_duration = max(float(duration), 0.1)  # âœ… ìµœì†Œ ì§€ì† ì‹œê°„ ë³´ì¥
            int_velocity = int(round(np.clip(100, 1, 127)))  # âœ… ì •ìˆ˜ ë³€í™˜

            if int_pitch < 0 or int_pitch > 127:
                print(f"âš ï¸ ì˜ëª»ëœ pitch ê°’ ë°œê²¬: {int_pitch}")
            if int_duration <= 0:
                print(f"âš ï¸ ì˜ëª»ëœ duration ê°’ ë°œê²¬: {int_duration}")
            if int_velocity < 1 or int_velocity > 127:
                print(f"âš ï¸ ì˜ëª»ëœ velocity ê°’ ë°œê²¬: {int_velocity}")

            midi_note = pretty_midi.Note(
                velocity=int_velocity,
                pitch=int_pitch,
                start=start_time,
                end=start_time + int_duration
            )
            inst.notes.append(midi_note)
            start_time += int_duration

    # ğŸ¹ ë©œë¡œë”” íŠ¸ë™
    melody_inst = pretty_midi.Instrument(program=0)  # Acoustic Grand Piano
    add_notes_to_instrument(melody_inst, melody, rhythm, 0, 127)
    midi.instruments.append(melody_inst)

    # ğŸ¸ ë² ì´ìŠ¤ íŠ¸ë™
    bass_inst = pretty_midi.Instrument(program=32)  # Acoustic Bass
    add_notes_to_instrument(bass_inst, bassline, bass_rhythm, 36, 127)
    midi.instruments.append(bass_inst)

    # ğŸ¥ ë“œëŸ¼ íŠ¸ë™
    drum_inst = pretty_midi.Instrument(program=0, is_drum=True)
    add_notes_to_instrument(drum_inst, drums, drum_rhythm, 35, 81)
    midi.instruments.append(drum_inst)

    # âœ… MIDI ì €ì¥
    midi.write(output_path)
    print(f"ğŸ¼ MIDI íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")


# âœ… ìƒì„±ëœ MIDI ì €ì¥
create_midi(generated_melody, generated_rhythm, generated_bassline, bass_rhythm, generated_drums, drum_rhythm, "generated_jazz.mid")