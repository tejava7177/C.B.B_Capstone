import tensorflow as tf
import numpy as np
import pretty_midi
from music_transformer_model import MusicTransformer

# âœ… ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
model_path = "/Users/simjuheun/Desktop/ê°œì¸í”„ë¡œì íŠ¸/C.B.B/genre_Model/jazz/music_transformer_jazz.keras"
model = tf.keras.models.load_model(model_path, custom_objects={"MusicTransformer": MusicTransformer})
print("ğŸµ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

# âœ… ì£¼ì–´ì§„ ì½”ë“œ ì§„í–‰
chord_progression = [
    [60, 64, 67],  # Cmaj7
    [67, 71, 74],  # Gmaj7
    [65, 68, 72],  # Fm
    [62, 65, 69],  # Dm
    [67, 71, 74],  # Gmaj7
    [71, 74, 77],  # Bdim
    [71, 75, 79],  # Bmaj7
    [64, 68, 72],  # Emaj7
    [71, 74, 77],  # Bdim
    [65, 69, 72],  # Fsus4
    [71, 75, 79]  # Bmaj7
]
chord_progression = np.array(chord_progression).astype(np.int32)


# âœ… ë©œë¡œë”” & ë¦¬ë“¬ ìƒì„± í•¨ìˆ˜ (ì…ë ¥ ì°¨ì› ë³€í™˜ + softmax ì•ˆì •í™”)
def generate_melody_and_rhythm(model, chord_progression, temperature=1.0):
    generated_melody = []
    generated_rhythm = []

    for chord in chord_progression:
        input_seq = np.expand_dims(chord, axis=0)  # (3,) -> (1, 3)
        predicted_probs = model.predict(input_seq, verbose=0)[0, -1, :]  # ë§ˆì§€ë§‰ step ì˜ˆì¸¡

        # ğŸ”¥ Temperature Sampling ì ìš© (softmax ë³€í™˜)
        predicted_probs = np.exp(predicted_probs / temperature)  # í™•ë¥  ì¡°ì •
        predicted_probs /= np.sum(predicted_probs)  # ì •ê·œí™” (í™•ë¥  ë¶„í¬)

        predicted_note = np.random.choice(len(predicted_probs), p=predicted_probs)
        predicted_rhythm = np.random.choice([0.25, 0.5, 1, 2], p=[0.3, 0.3, 0.3, 0.1])  # ğŸµ ëœë¤ ë¦¬ë“¬

        generated_melody.append(predicted_note)
        generated_rhythm.append(predicted_rhythm)

    return generated_melody, generated_rhythm


# âœ… ë©œë¡œë”” & ë¦¬ë“¬ ìƒì„±
generated_melody, generated_rhythm = generate_melody_and_rhythm(model, chord_progression)

# âœ… ìƒì„±ëœ ë©œë¡œë”” & ë¦¬ë“¬ ì¶œë ¥
print("ğŸ¶ ìƒì„±ëœ ë©œë¡œë””:", generated_melody)
print("ğŸ¥ ìƒì„±ëœ ë¦¬ë“¬:", generated_rhythm)


# âœ… MIDI ë³€í™˜ í•¨ìˆ˜ (ë…¸íŠ¸ ë²”ìœ„ ì¡°ì •)
def create_midi(melody, rhythm, output_path="generated_jazz.mid"):
    midi = pretty_midi.PrettyMIDI()
    instrument = pretty_midi.Instrument(program=0)  # Acoustic Grand Piano

    start_time = 0
    for note, duration in zip(melody, rhythm):
        midi_note = pretty_midi.Note(
            velocity=100,
            pitch=max(0, min(127, int(note))),  # MIDI ë²”ìœ„ ë‚´ì—ì„œ ì œí•œ
            start=start_time,
            end=start_time + duration
        )
        instrument.notes.append(midi_note)
        start_time += duration

    midi.instruments.append(instrument)
    midi.write(output_path)
    print(f"ğŸ¼ MIDI íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")


# âœ… ìƒì„±ëœ ë©œë¡œë””ë¥¼ MIDIë¡œ ë³€í™˜
create_midi(generated_melody, generated_rhythm, "generated_jazz.mid")