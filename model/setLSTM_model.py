import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Embedding
from tensorflow.keras.utils import to_categorical

# ë°ì´í„° ë¡œë“œ
chord_sequences = np.load("chord_sequences.npy")
chord_to_index = np.load("chord_to_index.npy", allow_pickle=True).item()
index_to_chord = {v: k for k, v in chord_to_index.items()}  # ì—­ë§¤í•‘

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
SEQUENCE_LENGTH = 3  # LSTMì´ ì´ì „ ëª‡ ê°œì˜ ì½”ë“œë¥¼ ë³´ê³  ë‹¤ìŒ ì½”ë“œ ì˜ˆì¸¡í• ì§€ ê²°ì •
NUM_CLASSES = len(chord_to_index)  # âš ï¸ ì „ì²´ ì½”ë“œ ê°œìˆ˜ ì¶”ê°€ (ì˜¤ë¥˜ í•´ê²°)

# ì…ë ¥(X)ê³¼ ì¶œë ¥(Y) ìƒì„±
X, Y = [], []

for seq in chord_sequences:
    for i in range(len(seq) - SEQUENCE_LENGTH):
        X.append(seq[i:i + SEQUENCE_LENGTH])
        Y.append(seq[i + SEQUENCE_LENGTH])

X = np.array(X)
Y = np.array(Y)

# ì¶œë ¥(Y)ì„ One-Hot Encoding ë³€í™˜
Y = to_categorical(Y, num_classes=NUM_CLASSES)

print(f"âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ! (X: {X.shape}, Y: {Y.shape})")
print(f"ğŸµ ê³ ìœ  ì½”ë“œ ê°œìˆ˜: {NUM_CLASSES}")

# ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
EMBEDDING_DIM = 16  # ì½”ë“œ ë²¡í„°í™” ì°¨ì›
LSTM_UNITS = 64  # LSTM ë‰´ëŸ° ê°œìˆ˜
BATCH_SIZE = 64
EPOCHS = 50

# LSTM ëª¨ë¸ ìƒì„±
model = Sequential([
    Embedding(input_dim=NUM_CLASSES, output_dim=EMBEDDING_DIM, input_length=SEQUENCE_LENGTH),
    LSTM(LSTM_UNITS, return_sequences=True),
    LSTM(LSTM_UNITS),
    Dense(64, activation='relu'),
    Dense(NUM_CLASSES, activation='softmax')  # ë‹¤ìŒ ì½”ë“œ ì˜ˆì¸¡ì„ ìœ„í•œ softmax ì¶œë ¥ì¸µ
])

# ëª¨ë¸ ì»´íŒŒì¼
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# ëª¨ë¸ í•™ìŠµ
history = model.fit(X, Y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.1)

# ëª¨ë¸ ì €ì¥
model.save("lstm_chord_model.h5")

print("âœ… LSTM ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ë° ì €ì¥ ì™„ë£Œ!")