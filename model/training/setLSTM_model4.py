import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping  # âœ… ì¡°ê¸° ì¢…ë£Œ ì¶”ê°€

# âœ… ê¸°ì¡´ ì½”ë“œ ì¸ë±ìŠ¤ ë¡œë“œ
chord_to_index = np.load("/Users/simjuheun/Desktop/ê°œì¸í”„ë¡œì íŠ¸/C.B.B/model/dataset/chord_to_index.npy", allow_pickle=True).item()
NUM_CHORDS = len(chord_to_index)  # âœ… ì´ 61ê°œ ì½”ë“œ ì‚¬ìš©

# âœ… ë°ì´í„°ì…‹ ë¡œë“œ
X = np.load("/Users/simjuheun/Desktop/ê°œì¸í”„ë¡œì íŠ¸/C.B.B/model/dataset/X.npy")
Y = np.load("/Users/simjuheun/Desktop/ê°œì¸í”„ë¡œì íŠ¸/C.B.B/model/dataset/Y.npy")

# âœ… ğŸ”¥ Y ë°ì´í„°ë¥¼ ì›-í•« ì¸ì½”ë”© ë³€í™˜
Y = to_categorical(Y, num_classes=NUM_CHORDS)

# âœ… LSTM ëª¨ë¸ ì •ì˜
model = Sequential([
    Embedding(input_dim=NUM_CHORDS, output_dim=64, input_length=3),
    LSTM(128, return_sequences=True),
    LSTM(128),
    Dense(NUM_CHORDS, activation='softmax')
])

# âœ… ëª¨ë¸ ì»´íŒŒì¼
model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])

# âœ… í•™ìŠµ ì„¤ì •
EPOCHS = 100  # ğŸ”¥ í•™ìŠµ íšŸìˆ˜ ì¦ê°€ (ê¸°ë³¸ 50 â†’ 100)
BATCH_SIZE = 256  # ğŸš€ ë°°ì¹˜ í¬ê¸° ì¦ê°€ (128 â†’ 256)

# âœ… ì¡°ê¸° ì¢…ë£Œ ì„¤ì • (10ë²ˆ ì—°ì† í–¥ìƒ ì—†ìœ¼ë©´ ì¢…ë£Œ)
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

print("ğŸš€ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
model.fit(X, Y, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping])

# âœ… ëª¨ë¸ ì €ì¥
MODEL_SAVE_PATH = "/Users/simjuheun/Desktop/ê°œì¸í”„ë¡œì íŠ¸/C.B.B/model/LSTM_model/lstm_chord_model4.h5"
model.save(MODEL_SAVE_PATH)

print(f"âœ… ìƒˆë¡œìš´ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {MODEL_SAVE_PATH}")